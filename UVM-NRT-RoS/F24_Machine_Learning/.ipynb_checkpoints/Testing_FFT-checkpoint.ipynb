{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "385a07d2-4344-42c6-8186-8322ab77c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import LeaveOneOut, train_test_split, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ece331a-603a-4db6-96da-41150ab50522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This serves to transpose the dataframe so that each frequency is a feature and each audio file is an entry\n",
    "def format_df(df, class_label):\n",
    "    new_df_dict = {}\n",
    "    frequencies = df[\"Frequency(Hz)\"].unique()\n",
    "    for frequency in frequencies:\n",
    "        if not np.isnan(frequency):\n",
    "            new_df_dict[frequency] = []\n",
    "            temp_df = df.loc[df[\"Frequency(Hz)\"] == frequency].reset_index()\n",
    "            for col in temp_df:\n",
    "                value_list = temp_df[col].values\n",
    "                val = float(value_list[0])\n",
    "                new_df_dict[frequency].append(val)\n",
    "    new_df = pd.DataFrame(new_df_dict)\n",
    "    new_df[\"Class\"] = class_label\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec114039-6cdd-4423-90b4-3bca5b7a2aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, model_name, class_labels):\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure()\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title(f'Confusion Matrix for {model_name}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa19e4bd-02a4-4b82-b831-8fe6c5b9ba04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(df):\n",
    "\n",
    "    # Prep features and target\n",
    "    features = df.drop(columns=[\"Class\"])\n",
    "    feature_names = features.columns\n",
    "    target = df.Class\n",
    "    class_labels = np.unique(target)\n",
    "    cv = LeaveOneOut()\n",
    "\n",
    "    # SVM\n",
    "    svm = SVC(kernel=\"linear\")\n",
    "    actual_class = []\n",
    "    predicted_class = []\n",
    "    \n",
    "    for train_index, test_index in cv.split(features):\n",
    "\n",
    "        # Splitting into training and testing\n",
    "        X_train, X_test = features.take(train_index), features.take(test_index)\n",
    "        y_train, y_test = target.take(train_index), target.take(test_index)\n",
    "\n",
    "        svm = svm.fit(X_train, y_train)\n",
    "        y_pred = svm.predict(X_test)\n",
    "\n",
    "        actual_class.append(y_test.item())\n",
    "        predicted_class.append(y_pred[0])\n",
    "\n",
    "    print(f\"SVM Accuracy: {accuracy_score(actual_class, predicted_class)*100:.2f}%\")\n",
    "    plot_confusion_matrix(actual_class, predicted_class, \"SVM\", class_labels)\n",
    "\n",
    "    # Random Forest\n",
    "    rf = RandomForestClassifier()\n",
    "    actual_class = []\n",
    "    predicted_class = []\n",
    "    \n",
    "    for train_index, test_index in cv.split(features):\n",
    "        \n",
    "        # Splitting into training and testing\n",
    "        X_train, X_test = features.take(train_index), features.take(test_index)\n",
    "        y_train, y_test = target.take(train_index), target.take(test_index)\n",
    "\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_test)\n",
    "\n",
    "        actual_class.append(y_test.item())\n",
    "        predicted_class.append(y_pred[0])\n",
    "\n",
    "    print(f\"RF Accuracy: {accuracy_score(actual_class, predicted_class)*100:.2f}%\")\n",
    "    plot_confusion_matrix(actual_class, predicted_class, \"RF\", class_labels)\n",
    "\n",
    "    # XGBoost \n",
    "    xgb = GradientBoostingClassifier()\n",
    "    actual_class = []\n",
    "    predicted_class = []\n",
    "    \n",
    "    for train_index, test_index in cv.split(features):\n",
    "        \n",
    "        # Splitting into training and testing\n",
    "        X_train, X_test = features.take(train_index), features.take(test_index)\n",
    "        y_train, y_test = target.take(train_index), target.take(test_index)\n",
    "\n",
    "        xgb.fit(X_train, y_train)\n",
    "        y_pred = xgb.predict(X_test)\n",
    "\n",
    "        actual_class.append(y_test.item())\n",
    "        predicted_class.append(y_pred[0])\n",
    "\n",
    "    print(f\"XGBoost Accuracy: {accuracy_score(actual_class, predicted_class)*100:.2f}%\")\n",
    "    plot_confusion_matrix(actual_class, predicted_class, \"XGBoost\", class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc20770e-4add-4c33-9198-6ac02ed43592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0.0  15.625    31.25   46.875     62.5   78.125    93.75   109.375  \\\n",
      "0   0.0   1.000   2.0000   3.0000   4.0000   5.0000   6.0000    7.0000   \n",
      "1   0.0  15.625  31.2500  46.8750  62.5000  78.1250  93.7500  109.3750   \n",
      "2   0.0   0.000  61.1685  48.1984  51.6137  49.6714  52.2828   41.6394   \n",
      "3   0.0   0.000  84.1489  73.7619  64.3837  76.6512  59.0365   49.3050   \n",
      "4   0.0   0.000  52.6081  51.4466  51.6991  40.3641  59.0093   29.1792   \n",
      "5   0.0   0.000  69.1186  50.2122  39.5148  55.1570  34.2372   55.4536   \n",
      "6   0.0   0.000  46.8842  66.0305  38.4985  46.8529  33.7761   55.3225   \n",
      "7   0.0   0.000  82.3337  79.0651  54.1015  79.4923  38.0339   68.9380   \n",
      "8   0.0   0.000  82.8838  71.0699  66.0605  68.8566  65.1396   43.7217   \n",
      "9   0.0   0.000  74.0737  67.4139  69.9484  70.5283  52.0391   60.6414   \n",
      "10  0.0   0.000  76.4999  68.9072  66.5104  68.1486  53.2844   49.8953   \n",
      "11  0.0   0.000  80.0200  61.2213  65.8027  73.1588  63.3765   54.8618   \n",
      "12  0.0   0.000  68.2431  79.7225  68.4383  59.0688  64.4453   42.7052   \n",
      "13  0.0   0.000  47.0010  58.1663  48.3756  38.2084  54.0391   19.1906   \n",
      "14  0.0   0.000  75.4228  69.1662  65.7367  64.8087  43.5825   69.7007   \n",
      "15  0.0   0.000  63.3411  48.9948  50.7159  48.0743  30.6883   50.1047   \n",
      "16  0.0   0.000  75.3671  75.0577  60.5479  72.8597  48.2374   55.4738   \n",
      "17  0.0   0.000  51.6956  47.4531  38.1592  39.9469  41.2875   35.7222   \n",
      "\n",
      "       125.0   140.625  ...   7859.375     7875.0   7890.625    7906.25  \\\n",
      "0     8.0000    9.0000  ...   503.0000   504.0000   505.0000   506.0000   \n",
      "1   125.0000  140.6250  ...  7859.3750  7875.0000  7890.6250  7906.2500   \n",
      "2    46.1482   26.4470  ...    17.0608    15.1540    12.5879    12.9395   \n",
      "3    76.7451   39.4716  ...    25.4532    27.5684    29.6791    27.3009   \n",
      "4    45.2400   27.0574  ...    16.7915    14.6032    13.1790    13.0853   \n",
      "5    27.4607   37.2382  ...    15.3612    14.1598    13.4274    13.4027   \n",
      "6    23.7041   41.2177  ...    16.7673    14.1344    13.1223    12.7275   \n",
      "7    50.8746   52.5460  ...    27.9384    27.5534    27.2772    28.8532   \n",
      "8    54.3688   40.2002  ...    24.4793    26.8118    32.2137    27.4753   \n",
      "9    44.8576   50.2074  ...    27.7580    27.5647    27.9664    29.7460   \n",
      "10   65.4668   35.3265  ...    27.2536    28.2763    27.3926    29.6206   \n",
      "11   44.7729   48.0182  ...    27.8071    27.4178    27.5549    30.1015   \n",
      "12   56.6813   51.5168  ...    32.2730    26.5945    29.5152    32.5979   \n",
      "13   55.4846   29.2449  ...    16.0081    14.8636    11.0277    12.4961   \n",
      "14   38.3201   51.9963  ...    27.5358    26.9760    28.6207    28.9208   \n",
      "15   37.5613   30.1178  ...    15.7220    15.1723    10.5532     9.9921   \n",
      "16   63.2607   19.9796  ...    27.7076    27.5760    29.3198    28.3832   \n",
      "17   38.1380   26.3744  ...    19.0987    16.9092    13.9668    14.4258   \n",
      "\n",
      "     7921.875     7937.5   7953.125    7968.75   7984.375     Class  \n",
      "0    507.0000   508.0000   509.0000   510.0000   511.0000  rain_med  \n",
      "1   7921.8750  7937.5000  7953.1250  7968.7500  7984.3750  rain_med  \n",
      "2     10.0761    10.0665     9.6454    10.0030     8.4414  rain_med  \n",
      "3     26.5543    30.4835    27.9034    28.7425    29.0903  rain_med  \n",
      "4      9.6507    11.6234     8.7550     8.2528    10.5057  rain_med  \n",
      "5      9.0259    10.3268    10.2662     8.1439     6.8920  rain_med  \n",
      "6     11.0954    10.1699     8.8098    10.4159     8.2172  rain_med  \n",
      "7     28.9870    27.6222    31.3592    29.0801    27.0175  rain_med  \n",
      "8     25.9743    31.2988    28.6097    30.7393    30.8903  rain_med  \n",
      "9     27.6769    29.2936    30.2318    27.9710    30.9116  rain_med  \n",
      "10    28.1577    28.3947    29.6396    29.6736    28.4517  rain_med  \n",
      "11    28.5746    29.4780    28.6845    30.1507    29.4256  rain_med  \n",
      "12    25.2607    33.1684    29.8215    27.5279    38.3068  rain_med  \n",
      "13     9.2082     8.8789     8.4519     7.3841     6.7190  rain_med  \n",
      "14    29.3007    28.2364    31.6244    28.9999    30.3361  rain_med  \n",
      "15    13.5631     7.1281     9.6497     6.2050     5.9161  rain_med  \n",
      "16    25.6038    31.6674    28.4834    24.6550    33.3704  rain_med  \n",
      "17    14.1342    11.7065    14.2359    11.3447    10.7680  rain_med  \n",
      "\n",
      "[18 rows x 513 columns]\n"
     ]
    }
   ],
   "source": [
    "fft_files = glob.glob(\"../Soheyl_Codes/Data/*\")\n",
    "df_list = []\n",
    "for file in fft_files:\n",
    "    df = pd.read_csv(file)\n",
    "    class_label = file.split('/')[-1].split('.')[0]\n",
    "    new_df = format_df(df, class_label)\n",
    "    print(new_df)\n",
    "    break\n",
    "    df_list.append(new_df)\n",
    "\n",
    "# all_classes_df = pd.concat(df_list, ignore_index=True).dropna()\n",
    "# run_models(all_classes_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
