{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ca5d786-b560-4e24-983f-280883144df8",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This file serves to recreate, with some adjustments, our work from last semester with new audio samples. We extract 8 total features from the .wav files:\n",
    "* Autocorrelation Coefficient (ACC): measures the linear relation between an observation at sample N and the observations at previous samples \n",
    "* Zero Crossing Rate (ZCR): the rate at which a signal changes from positive to zero to negative or from negative to zero to positive\n",
    "* Temporal Entropy (Ht): The entropy of an audio signal is a measure of energy dispersion. In the temporal domain, values below 0.7 indicate a brief concentration of energy (few miliseconds), while values close 1 indicate low concentration of energy, no peaks, smooth and constant background noise.\n",
    "* Spectral Entropy (Hf): Compute different entropies based on the average spectrum, its variance, and its maxima\n",
    "* Acoustic Complexity Index (ACI): contrasts the amplitude difference between one short time step (e.g. 0.03 s) and the next, within a narrow frequency band (e.g. 62 Hz)\n",
    "* Spectral Cover (SC)\n",
    "  * LFC: Proportion of the LF bandwidth of the spectrogram with activity above the threshold.\n",
    "  * MFC: Proportion of the MF bandwidth of the spectrogram with activity above the threshold.\n",
    "  * HFC: Proportion of the HF bandwidth of the spectrogram with activity above the threshold.\n",
    "\n",
    "Using these features, we also implement the following models:\n",
    "* Support Vector Machine (SVM)\n",
    "* Random Forests (RF)\n",
    "* XGBoost (XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "30f05adf-e131-42fa-bffd-04a6bdd62147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import librosa.feature\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import LeaveOneOut, train_test_split, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "import maad\n",
    "from maad.features import temporal_entropy\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbc87ea-e500-439a-81a6-b65034cfd355",
   "metadata": {},
   "source": [
    "### Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "20663dc0-6086-4950-a601-93ee12e35bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Locate all audio files from new testing samples folder\n",
    "    all_audio_files = glob.glob(\"../microphone-sampling/NewTestingSamples/*/*\")\n",
    "\n",
    "    # Dictionary to store file names by class\n",
    "    class_dict = {}\n",
    "    for file in all_audio_files:\n",
    "        file_class = file.split('/')[3]\n",
    "        if file_class not in class_dict:\n",
    "            class_dict[file_class] = []\n",
    "        class_dict[file_class].append(file)\n",
    "\n",
    "    # Extract all features for each class and store in dataframes\n",
    "    all_class_dfs = []\n",
    "    for key in class_dict:\n",
    "        df = wav_to_audio_features(class_dict[key])\n",
    "        # Plotting correlation matrix\n",
    "        # corr_matrix = df.corr()\n",
    "        # fig = plt.figure()\n",
    "        # sns.heatmap(np.abs(corr_matrix), annot=True, cmap='inferno', linewidths=0.5)\n",
    "        # plt.title(key + ' Correlation Matrix Heatmap')\n",
    "        # plt.show()\n",
    "        df[\"Class\"] = key\n",
    "        all_class_dfs.append(df)\n",
    "\n",
    "    # All data from all audio files (labeled) \n",
    "    all_classes_df = pd.concat(all_class_dfs, ignore_index=True)\n",
    "\n",
    "    # Running ML models\n",
    "    run_models(all_classes_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d2812e-a1c0-44b5-93eb-97125aa87fbc",
   "metadata": {},
   "source": [
    "### wav_to_audio_features loads and then extracts features from inputted list of .wav file paths and returns features in form of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "3c5673cb-a8fa-40d3-98c8-1f7996016ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav_to_audio_features(files):\n",
    "    \n",
    "    ACC_list = []\n",
    "    ZCR_list = []\n",
    "    Ht_list = []\n",
    "    Hf_list = []\n",
    "    ACI_list = []\n",
    "    SC_LFC_list = [] \n",
    "    SC_MFC_list = []\n",
    "    SC_HFC_list = []\n",
    "    \n",
    "    # os.listdir gets all files in the specified directory\n",
    "    for filename in files:\n",
    "        # Librosa/File setup\n",
    "        x, sr = librosa.load(filename)\n",
    "\n",
    "        # Get a spectrogram to use as the input to the spectral_entropy, ACI, and spectral cover functions\n",
    "        # f is the array of sample frequencies\n",
    "        # t is the array of segment times\n",
    "        # sxx is a spectrogram of x (the audio signal, originally in the time domain\n",
    "        f, t, sxx = scipy.signal.spectrogram(x, fs=sr)\n",
    "\n",
    "        # Extracting Auto Correlation Coefficient\n",
    "        acc = sm.tsa.acf(x, nlags=2000)\n",
    "        ACC_list.append(np.mean(acc))\n",
    "\n",
    "        # Extracting Zero Crossing Rate\n",
    "        zero_crossings = librosa.feature.zero_crossing_rate(x, pad=False)\n",
    "        fixed_length_zcr = librosa.util.fix_length(zero_crossings[0], size=1000, mode='edge')\n",
    "        ZCR_list.append(np.mean(fixed_length_zcr))\n",
    "\n",
    "        # Extracting Temporal Entropy (Ht)\n",
    "        Ht = maad.features.temporal_entropy(x)\n",
    "        Ht_list.append(Ht)\n",
    "\n",
    "        # Extract Spectral Entropy (Hf)\n",
    "        # Use EAS because that is the Entropy of Average Spectrum\n",
    "        EAS, ECU, ECV, EPS, EPS_KURT, EPS_SKEW = maad.features.spectral_entropy(sxx, f)\n",
    "        Hf = EAS\n",
    "        Hf_list.append(Hf)\n",
    "\n",
    "        # Acoustic Complexity Index (ACI) \n",
    "        # Use sxx from the spectrogram\n",
    "        _, _, ACI = maad.features.acoustic_complexity_index(sxx)\n",
    "        ACI_list.append(ACI)\n",
    "\n",
    "        # Spectral Cover (SC)\n",
    "        # Using the maad spectrogram for SC to get the ext variable,\n",
    "        # to be able to get the spectrogram with no noise.\n",
    "        sxx_power, tn, fn, ext = maad.sound.spectrogram(x, sr)\n",
    "        sxx_no_noise = maad.sound.median_equalizer(sxx_power, display=False, extent=ext)\n",
    "        sxx_dB_no_noise = maad.util.power2dB(sxx_no_noise)\n",
    "        LFC, MFC, HFC = maad.features.spectral_cover(sxx_dB_no_noise, fn)\n",
    "        SC_LFC_list.append(LFC)\n",
    "        SC_MFC_list.append(MFC)\n",
    "        SC_HFC_list.append(HFC)\n",
    "\n",
    "    #Convert all lists into arrays to return and be used by\n",
    "    ACC_array = np.array(ACC_list)\n",
    "    ZCR_array = np.array(ZCR_list)\n",
    "    Ht_array = np.array(Ht_list)\n",
    "    Hf_array = np.array(Hf_list)\n",
    "    ACI_array = np.array(ACI_list)\n",
    "    SC_LFC_array = np.array(SC_LFC_list)\n",
    "    SC_MFC_array = np.array(SC_MFC_list)\n",
    "    SC_HFC_array = np.array(SC_HFC_list)\n",
    "\n",
    "    # Create dataframe from all features\n",
    "    features_dict = {\"Avg_ACC\": ACC_array, \"Avg_ZCR\": ZCR_array, \"Ht\": Ht_array, \"Hf\": Hf_array, \"ACI\": ACI_array, \"SC_LFC\": SC_LFC_array, \n",
    "                     \"SC_MFC\": SC_MFC_array, \"SC_HFC\": SC_HFC_array}\n",
    "    features_df = pd.DataFrame(features_dict)\n",
    "    \n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e6ef9160-4573-47f4-851c-7fab849be394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(df):\n",
    "\n",
    "    # Prep features and target\n",
    "    features = df.drop(columns=[\"Class\"])\n",
    "    target = df.Class\n",
    "    cv = LeaveOneOut()\n",
    "\n",
    "    # SVM\n",
    "    svm = SVC(kernel=\"linear\")\n",
    "    actual_class = []\n",
    "    predicted_class = []\n",
    "    \n",
    "    for train_index, test_index in cv.split(features):\n",
    "\n",
    "        # Splitting into training and testing\n",
    "        X_train, X_test = features.take(train_index), features.take(test_index)\n",
    "        y_train, y_test = target[train_index], target[test_index]\n",
    "\n",
    "        svm.fit(X_train, y_train)\n",
    "        y_pred = svm.predict(X_test)\n",
    "\n",
    "        actual_class.append(y_test.item())\n",
    "        predicted_class.append(y_pred[0])\n",
    "\n",
    "    print(f\"SVM Accuracy: {accuracy_score(actual_class, predicted_class)*100:.2f}%\")\n",
    "\n",
    "    # svm = SVC(kernel=\"linear\")\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3)\n",
    "    # svm.fit(X_train, y_train)\n",
    "    # y_pred = svm.predict(X_test)\n",
    "    # print(f\"SVM Accuracy: {accuracy_score(y_test, y_pred)*100:.2f}%\")\n",
    "\n",
    "    \n",
    "    # Random Forest\n",
    "    rf = RandomForestClassifier()\n",
    "    actual_class = []\n",
    "    predicted_class = []\n",
    "    \n",
    "    for train_index, test_index in cv.split(features):\n",
    "        \n",
    "        # Splitting into training and testing\n",
    "        X_train, X_test = features.take(train_index), features.take(test_index)\n",
    "        y_train, y_test = target[train_index], target[test_index]\n",
    "\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_test)\n",
    "\n",
    "        actual_class.append(y_test.item())\n",
    "        predicted_class.append(y_pred[0])\n",
    "\n",
    "    print(f\"RF Accuracy: {accuracy_score(actual_class, predicted_class)*100:.2f}%\")\n",
    "\n",
    "    # XGBoost \n",
    "    xgb = GradientBoostingClassifier()\n",
    "    actual_class = []\n",
    "    predicted_class = []\n",
    "    \n",
    "    for train_index, test_index in cv.split(features):\n",
    "        \n",
    "        # Splitting into training and testing\n",
    "        X_train, X_test = features.take(train_index), features.take(test_index)\n",
    "        y_train, y_test = target[train_index], target[test_index]\n",
    "\n",
    "        xgb.fit(X_train, y_train)\n",
    "        y_pred = xgb.predict(X_test)\n",
    "\n",
    "        actual_class.append(y_test.item())\n",
    "        predicted_class.append(y_pred[0])\n",
    "\n",
    "    print(f\"XGBoost Accuracy: {accuracy_score(actual_class, predicted_class)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "d94d8584-b8e0-4a3f-b58f-8dd59e52c672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 61.45%\n",
      "RF Accuracy: 89.76%\n",
      "XGBoost Accuracy: 84.34%\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
